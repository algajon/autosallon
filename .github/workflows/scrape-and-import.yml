name: Scrape & Import (Hostinger via SSH tunnel)

on:
  workflow_dispatch:
  schedule:
    - cron: "17 * * * *" # run hourly at :17

permissions:
  contents: read

concurrency:
  group: scrape-import
  cancel-in-progress: false

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 45

    env:
      # Local endpoint for the SSH tunnel (runner side)
      DB_HOST: 127.0.0.1
      DB_PORT: 3307

      # Where your scraper writes the CSV
      CSV_DIR: ${{ secrets.CSV_DIR || 'scripts' }}
      CSV_NAME: cars.csv
      KRW_EUR: ${{ secrets.KRW_EUR != '' && secrets.KRW_EUR || '0.000615' }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install system deps (MySQL client, SSH)
        run: |
          sudo apt-get update
          sudo apt-get install -y mysql-client openssh-client
      # --- SSH key-only auth (no password fallback) ---
      - name: Prepare SSH key (key-only; no password)
        id: prep-ssh
        env:
          SSH_KEY:  ${{ secrets.HOSTINGER_SSH_KEY }}
        run: |
          set -euo pipefail
          mkdir -p ~/.ssh && chmod 700 ~/.ssh
          echo "$SSH_KEY" > ~/.ssh/id_ed25519
          chmod 600 ~/.ssh/id_ed25519
          # Fail early if key is invalid or passphrase-protected
          if ! ssh-keygen -y -f ~/.ssh/id_ed25519 >/dev/null 2>&1; then
            echo "The private key in HOSTINGER_SSH_KEY appears invalid or passphrase-protected."
            exit 1
          fi
          # SSH client defaults (force key-only)
          cat > ~/.ssh/config <<'CFG'
          Host *
            ServerAliveInterval 30
            ServerAliveCountMax 3
            IdentitiesOnly yes
            PreferredAuthentications publickey
            PasswordAuthentication no
            StrictHostKeyChecking no
          CFG
      - name: Try SSH auth once (verbose)
        env:
          SSH_HOST: ${{ secrets.HOSTINGER_SSH_HOST }}
          SSH_PORT: ${{ secrets.HOSTINGER_SSH_PORT }}
          SSH_USER: ${{ secrets.HOSTINGER_SSH_USER }}
        run: |
          set -e
          ssh -vvv -o IdentitiesOnly=yes -i ~/.ssh/id_ed25519 \
              -p "$SSH_PORT" "$SSH_USER@$SSH_HOST" "echo 'Auth OK'; exit"
      - name: Start SSH tunnel to Hostinger (MySQL)
        env:
          SSH_HOST: ${{ secrets.HOSTINGER_SSH_HOST }}
          SSH_PORT: ${{ secrets.HOSTINGER_SSH_PORT }}
          SSH_USER: ${{ secrets.HOSTINGER_SSH_USER }}
          DB_PORT:  ${{ env.DB_PORT }}
        run: |
          set -euo pipefail
          ssh -f -N \
            -o ExitOnForwardFailure=yes \
            -o IdentitiesOnly=yes -i ~/.ssh/id_ed25519 \
            -L ${DB_PORT}:127.0.0.1:3306 \
            -p "${SSH_PORT}" "${SSH_USER}@${SSH_HOST}"
          # Wait for tunnel
          for i in {1..20}; do
            if ss -lnt | grep -q ":${DB_PORT}"; then
              echo "Tunnel up on port ${DB_PORT}"
              exit 0
            fi
            sleep 0.5
          done
          echo "Tunnel did not open" >&2
          exit 1
      # --- Run your scraper (writes CSV to $CSV_DIR/$CSV_NAME) ---
      - name: Install Python requirements
        run: |
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
      - name: Prepare unique Chrome profile dir
        run: |
          echo "CHROME_USER_DATA_DIR=$RUNNER_TEMP/chrome-${GITHUB_RUN_ID}-${GITHUB_RUN_ATTEMPT}" >> $GITHUB_ENV
          mkdir -p "$RUNNER_TEMP/chrome-${GITHUB_RUN_ID}-${GITHUB_RUN_ATTEMPT}"
      - name: Clean stale Chrome (best-effort)
        run: |            
            pkill -f chrome || true
            pkill -f chromedriver || true
      - name: Run scraper
        env:
          KRW_EUR: ${{ secrets.KRW_EUR }}
        run: |
          set -e
          mkdir -p "$CSV_DIR"
          # === replace with your real entrypoint if different ===
          python scripts/github.py
          # ======================================================
          test -s "${CSV_DIR}/${CSV_NAME}" || (echo "CSV not found at ${CSV_DIR}/${CSV_NAME}" >&2; exit 1)
          ls -lh "${CSV_DIR}/${CSV_NAME}"
      # --- Import CSV into MySQL over the tunnel ---
      - name: Import CSV into MySQL (UPSERT)
        env:
          DB_NAME: ${{ secrets.DB_DATABASE }}
          DB_USER: ${{ secrets.DB_USERNAME }}
          DB_PASS: ${{ secrets.DB_PASSWORD }}
        run: |
          set -euo pipefail

          [[ -n "${DB_NAME:-}" ]] || { echo "DB_NAME is empty/missing"; exit 1; }
          [[ -n "${DB_USER:-}" ]] || { echo "DB_USER is empty/missing"; exit 1; }
          [[ -n "${DB_PASS:-}" ]] || { echo "DB_PASS is empty/missing"; exit 1; }

          CONF="$(mktemp)"
          chmod 600 "$CONF"
          cat > "$CONF" <<EOF
          [client]
          user=${DB_USER}
          password=${DB_PASS}
          host=${DB_HOST}
          port=${DB_PORT}
          database=${DB_NAME}
          local-infile=1
          protocol=TCP
          EOF

          CSV_PATH="$(pwd)/${CSV_DIR}/${CSV_NAME}"
          MYSQL_BASE="mysql --defaults-extra-file=$CONF"

          echo "MySQL ping/version:"
    
          $MYSQL_BASE -e "SELECT VERSION() AS version, @@skip_name_resolve AS skip_name_resolve;"

          $MYSQL_BASE <<'SQL'
          DROP TABLE IF EXISTS stg_encar;
          CREATE TABLE stg_encar (
            prodhuesi        VARCHAR(80),
            modeli           VARCHAR(120),
            varianti         VARCHAR(160),
            viti             VARCHAR(8),
            cmimi_eur        INT,
            kilometrazhi_km  INT,
            karburanti       VARCHAR(40),
            ngjyra           VARCHAR(40),
            transmisioni     VARCHAR(40),
            uleset           VARCHAR(8),
            vin              VARCHAR(40),
            engine_cc        INT,
            images           TEXT,
            listing_url      VARCHAR(512),
            opsionet         MEDIUMTEXT,
            raporti_url      TEXT
          ) DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
          SQL

          $MYSQL_BASE --execute="
          LOAD DATA LOCAL INFILE '${CSV_PATH}'
          INTO TABLE stg_encar
          CHARACTER SET utf8mb4
          FIELDS TERMINATED BY ','  ENCLOSED BY '\"'
          LINES TERMINATED BY '\n'
          IGNORE 1 LINES
          (prodhuesi, modeli, varianti, viti, cmimi_eur, kilometrazhi_km, karburanti, ngjyra,
           transmisioni, uleset, vin, engine_cc, images, listing_url, opsionet, raporti_url);
          "

          $MYSQL_BASE <<'SQL'
          CREATE TABLE IF NOT EXISTS vehicles LIKE stg_encar;
          ALTER TABLE vehicles
          ADD UNIQUE KEY uniq_listing_url (listing_url(255));
          INSERT INTO vehicles (
            prodhuesi, modeli, varianti, viti, cmimi_eur, kilometrazhi_km, karburanti, ngjyra,
            transmisioni, uleset, vin, engine_cc, images, listing_url, opsionet, raporti_url
          )
          SELECT
          prodhuesi, modeli, varianti, viti, cmimi_eur, kilometrazhi_km, karburanti, ngjyra,
          transmisioni, uleset, vin, engine_cc, images, listing_url, opsionet, raporti_url
          FROM stg_encar
          ON DUPLICATE KEY UPDATE
            prodhuesi=VALUES(prodhuesi),
            modeli=VALUES(modeli),
            varianti=VALUES(varianti),
            viti=VALUES(viti),
            cmimi_eur=VALUES(cmimi_eur),
            kilometrazhi_km=VALUES(kilometrazhi_km),
            karburanti=VALUES(karburanti),
            ngjyra=VALUES(ngjyra),
            transmisioni=VALUES(transmisioni),
            uleset=VALUES(uleset),
            vin=VALUES(vin),
            engine_cc=VALUES(engine_cc),
            images=VALUES(images),
            opsionet=VALUES(opsionet),
            raporti_url=VALUES(raporti_url);
          SQL

          shred -u "$CONF" || rm -f "$CONF"
